{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\himal\\anaconda3\\envs\\Aro\\lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:13: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\himal\\anaconda3\\envs\\Aro\\lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import ttk, messagebox\n",
    "import os\n",
    "import threading\n",
    "import joblib\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import pandas as pd\n",
    "import time\n",
    "import csv\n",
    "from fpdf import FPDF\n",
    "import datetime\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if __file__ is available (in scripts), else use the current working directory (for Jupyter)\n",
    "try:\n",
    "    script_dir = os.path.dirname(os.path.abspath(__file__))\n",
    "except NameError:\n",
    "    script_dir = os.getcwd()  # Fallback to the current working directory in Jupyter or interactive environments\n",
    "\n",
    "# Define the directory paths for application forms and the main script\n",
    "applications_dir = os.path.join(script_dir, 'Search report', 'Application Forms')\n",
    "main_script_dir = os.path.join(script_dir, 'Search report')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SearchReportPDF(FPDF):\n",
    "    def __init__(self, application_no, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.application_no = application_no  # Store the application number\n",
    "\n",
    "    def header(self):\n",
    "        # Title outside the box, inside the top margin\n",
    "        self.set_y(10)  # Position inside the top margin\n",
    "        self.set_font(\"Arial\", 'B', 14)\n",
    "        self.cell(0, 10, \"INTERNATIONAL SEARCH REPORT\", 0, 1, 'C')\n",
    "        self.set_font(\"Arial\", '', 12)\n",
    "        # Insert the dynamically provided application number\n",
    "        self.cell(0, 10, f\"International Application No.: {self.application_no}\", 0, 1, 'C')\n",
    "        self.ln(2)\n",
    "        \n",
    "    def section_title(self, title):\n",
    "        self.set_font(\"Arial\", 'B', 12)\n",
    "        self.cell(0, 10, title, 0, 1, 'L')\n",
    "        self.ln(1)\n",
    "\n",
    "    def section_body(self, body):\n",
    "        self.set_font(\"Arial\", '', 9)\n",
    "        self.multi_cell(self.w - 2 * self.l_margin, 10, body)\n",
    "        self.ln(1)\n",
    "\n",
    "    def table_with_title(self, title, headers, data, col_widths):\n",
    "        # Ensure table respects margins\n",
    "        total_width = sum(col_widths)\n",
    "        if total_width > (self.w - 2 * self.l_margin):\n",
    "            scale_factor = (self.w - 2 * self.l_margin) / total_width\n",
    "            col_widths = [width * scale_factor for width in col_widths]\n",
    "        \n",
    "        # Add table title\n",
    "        self.section_title(title)\n",
    "        \n",
    "        # Add table headers\n",
    "        self.set_font(\"Arial\", 'B', 8)\n",
    "        line_height = self.font_size * 2\n",
    "        self.set_fill_color(200, 200, 200)  # Light gray background for headers\n",
    "        for header, width in zip(headers, col_widths):\n",
    "            self.cell(width, line_height, header, align='C', fill=True)\n",
    "        self.ln(line_height)\n",
    "        \n",
    "        # Add a line below the header\n",
    "        self.line(self.l_margin, self.get_y(), self.w - self.r_margin, self.get_y())\n",
    "        \n",
    "        # Add table data with horizontal lines between rows\n",
    "        self.set_font(\"Arial\", '', 8)\n",
    "        for row in data:\n",
    "            max_line_height = max(self.get_string_height(width, datum) for datum, width in zip(row, col_widths))\n",
    "            y_before = self.get_y()\n",
    "            for datum, width in zip(row, col_widths):\n",
    "                # Use multi_cell to handle text wrapping\n",
    "                x_before = self.get_x()\n",
    "                self.multi_cell(width, 5, datum, align='L')\n",
    "                self.set_xy(x_before + width, y_before)\n",
    "            self.ln(max_line_height)\n",
    "            # Add a horizontal line after each row\n",
    "            self.line(self.l_margin, self.get_y(), self.w - self.r_margin, self.get_y())\n",
    "        self.ln(5)\n",
    "\n",
    "    def get_string_height(self, width, text):\n",
    "        # Helper function to calculate height of a multi-line string\n",
    "        num_lines = self.get_string_width(text) / width\n",
    "        return (num_lines + 1) * self.font_size * 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load submitted patent applications\n",
    "def load_patent_applications():\n",
    "    applications = []\n",
    "    if os.path.exists(applications_dir):\n",
    "        applications = [app for app in os.listdir(applications_dir) if os.path.isdir(os.path.join(applications_dir, app))]\n",
    "    return applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load and display selected patent application details\n",
    "def load_application_details(event):\n",
    "    selected_app = application_listbox.get(application_listbox.curselection())\n",
    "    display_application_details(selected_app)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to display application details\n",
    "def display_application_details(title):\n",
    "    patent_dir = os.path.join(applications_dir, title)\n",
    "\n",
    "    # Clear previous details\n",
    "    details_textbox.delete(1.0, tk.END)\n",
    "\n",
    "    # Load and display CSV data\n",
    "    csv_file = os.path.join(patent_dir, f'{title}.csv')\n",
    "    if os.path.exists(csv_file):\n",
    "        with open(csv_file, 'r') as file:\n",
    "            reader = csv.reader(file)\n",
    "            headers = next(reader)\n",
    "            data = next(reader)\n",
    "            details_textbox.insert(tk.END, f\"Patent Title: {title}\\n\\n\")\n",
    "            for header, value in zip(headers, data):\n",
    "                details_textbox.insert(tk.END, f\"{header.replace('_', ' ').capitalize()}: {value}\\n\")\n",
    "\n",
    "    # List uploaded files\n",
    "    details_textbox.insert(tk.END, \"\\nUploaded Documents:\\n\")\n",
    "    for file in os.listdir(patent_dir):\n",
    "        if file.endswith(('.pdf', '.jpeg')):\n",
    "            details_textbox.insert(tk.END, f\"- {file}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to predict IPC code in a background thread\n",
    "def predict_ipc_code():\n",
    "    try:\n",
    "        selected_app = application_listbox.get(application_listbox.curselection())\n",
    "        if selected_app:\n",
    "            # Path to the CSV file of the selected patent application\n",
    "            application_folder = os.path.join(applications_dir, selected_app)\n",
    "\n",
    "            # Create a new thread to run the IPC prediction and pass 'selected_app'\n",
    "            thread = threading.Thread(target=run_ipc_prediction, args=(application_folder, selected_app))\n",
    "            thread.start()\n",
    "        else:\n",
    "            messagebox.showwarning(\"No Selection\", \"Please select a patent application to predict the IPC code.\")\n",
    "    except IndexError:\n",
    "        messagebox.showwarning(\"No Selection\", \"Please select a patent application to predict the IPC code.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to run the IPC prediction and show the progress bar\n",
    "def run_ipc_prediction(application_folder, selected_app):\n",
    "    try:\n",
    "        # Show progress bar\n",
    "        progress_window = tk.Toplevel(root)\n",
    "        progress_window.title(\"Predicting IPC Code...\")\n",
    "        progress_label = tk.Label(progress_window, text=\"Please wait, predicting IPC code...\")\n",
    "        progress_label.pack(pady=10)\n",
    "        progress_bar = ttk.Progressbar(progress_window, orient=\"horizontal\", length=300, mode=\"indeterminate\")\n",
    "        progress_bar.pack(pady=20)\n",
    "        progress_bar.start()\n",
    "\n",
    "        # Load classifier, label encoder, and SentenceTransformer model on CPU\n",
    "        classifier_file_path = os.path.join(main_script_dir, 'ipc_section_classifier.pkl')\n",
    "        label_encoder_file_path = os.path.join(main_script_dir, 'ipc_section_label_encoder.pkl')\n",
    "        model = SentenceTransformer('AI-Growth-Lab/PatentSBERTa')  # Force model to run on CPU\n",
    "\n",
    "        loaded_classifier = joblib.load(classifier_file_path)\n",
    "        loaded_label_encoder = joblib.load(label_encoder_file_path)\n",
    "\n",
    "        # CSV file path\n",
    "        csv_file_path = os.path.join(application_folder, f'{os.path.basename(application_folder)}.csv')\n",
    "        if not os.path.exists(csv_file_path):\n",
    "            raise FileNotFoundError(f\"CSV file not found at {csv_file_path}\")\n",
    "\n",
    "        # Load the CSV into a pandas DataFrame\n",
    "        df = pd.read_csv(csv_file_path)\n",
    "\n",
    "        # Debugging: Print the column names\n",
    "        print(\"CSV Column Names:\", df.columns.tolist())\n",
    "\n",
    "        # Check for required columns\n",
    "        if 'claims' not in df.columns or 'title' not in df.columns:\n",
    "            raise ValueError(f\"'claims' or 'title' column not found in {csv_file_path}. Found columns: {df.columns.tolist()}\")\n",
    "\n",
    "        # Initialize predictions list\n",
    "        predictions = []\n",
    "\n",
    "        # Generate a publication number based on the current time\n",
    "        publication_number = int(time.time())\n",
    "\n",
    "        # Iterate through each row in the dataframe\n",
    "        for index, row in df.iterrows():\n",
    "            claims = row['claims']\n",
    "            title = row['title']\n",
    "\n",
    "            if claims:\n",
    "                # Encode the input claims into embeddings\n",
    "                claims_embedding = model.encode([claims])\n",
    "\n",
    "                # Predict using the loaded classifier\n",
    "                predicted_encoded_section = loaded_classifier.predict(claims_embedding)\n",
    "\n",
    "                # Decode the predicted section back to the IPC format\n",
    "                predicted_section = loaded_label_encoder.inverse_transform(predicted_encoded_section)\n",
    "\n",
    "                # Append the results to the predictions list\n",
    "                predictions.append([publication_number, title, predicted_section[0]])\n",
    "\n",
    "                # Display the predicted IPC code in the title_ipc_label in the desired format\n",
    "                title_ipc_label.config(text=f\"{title} - Classification ({predicted_section[0]})\")\n",
    "\n",
    "        # Convert predictions to a DataFrame and save to CSV\n",
    "        predictions_df = pd.DataFrame(predictions, columns=['publication_number', 'title', 'ipc'])\n",
    "        output_csv_file_path = os.path.join(application_folder, 'test_ipc_codes.csv')\n",
    "        predictions_df.to_csv(output_csv_file_path, mode='w', header=True, index=False)\n",
    "\n",
    "        # Stop the progress bar and close the window when done\n",
    "        progress_bar.stop()\n",
    "        progress_window.destroy()\n",
    "\n",
    "        # Display the \"Generate Search Report\" button after prediction\n",
    "        generate_report_button = ttk.Button(frame_right, text=\"Generate Search Report\", \n",
    "                                            command=lambda: generate_search_report(application_folder))\n",
    "        generate_report_button.pack(pady=10)\n",
    "\n",
    "        messagebox.showinfo(\"Success\", f\"IPC code predicted and saved for {selected_app}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        progress_window.destroy()\n",
    "        messagebox.showerror(\"Error\", f\"Failed to predict IPC code: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate_search_report function to handle dynamic folder\n",
    "def generate_search_report(application_folder):\n",
    "    try:\n",
    "        # Load the predicted IPC code data from the generated CSV\n",
    "        csv_file_path = os.path.join(application_folder, 'test_ipc_codes.csv')\n",
    "        if not os.path.exists(csv_file_path):\n",
    "            raise FileNotFoundError(f\"CSV file not found at {csv_file_path}\")\n",
    "\n",
    "        # Load the CSV data into a DataFrame\n",
    "        df = pd.read_csv(csv_file_path)\n",
    "\n",
    "        # Generate the current year and a random unique 6-digit number\n",
    "        current_year = datetime.datetime.now().year\n",
    "        unique_number = random.randint(100000, 999999)\n",
    "\n",
    "        # Create the dynamically generated International Application Number\n",
    "        application_no = f\"PCT/IB{current_year}/{unique_number}\"\n",
    "\n",
    "        # Create instance of FPDF with dynamic application number\n",
    "        pdf = SearchReportPDF(application_no, 'P', 'mm', 'A4')\n",
    "\n",
    "        # Set 3 cm margins\n",
    "        pdf.set_margins(30, 30, 30)\n",
    "\n",
    "        # Add a page\n",
    "        pdf.add_page()\n",
    "\n",
    "        # Keep duplicates for CLASSIFICATION OF SUBJECT MATTER\n",
    "        ipc_codes_classification = \"; \".join(df['ipc'].tolist())\n",
    "\n",
    "        # Remove duplicate IPC codes for FIELDS SEARCHED by converting to a set and then join them into a single string\n",
    "        ipc_codes_fields_searched = \"; \".join(sorted(set(df['ipc'].tolist())))\n",
    "\n",
    "        # Section title and body for CLASSIFICATION OF SUBJECT MATTER\n",
    "        pdf.section_title(\"CLASSIFICATION OF SUBJECT MATTER\")\n",
    "        pdf.section_body(ipc_codes_classification)\n",
    "\n",
    "        # **New**: Extract and add the Patent Title after \"CLASSIFICATION OF SUBJECT MATTER\"\n",
    "        if 'title' in df.columns:\n",
    "            title = df['title'].iloc[0]  # Get the first title from the CSV (assuming all rows have the same title)\n",
    "            pdf.section_title(\"Patent Title\")\n",
    "            pdf.section_body(title)\n",
    "\n",
    "        # Replace A01C with ipc_codes in the \"FIELDS SEARCHED\" section, removing duplicates\n",
    "        pdf.section_title(\"FIELDS SEARCHED\")\n",
    "        pdf.section_body(f\"Minimum documentation searched (classification symbols): {ipc_codes_fields_searched}\\n\"\n",
    "                        \"Documentation searched other than minimum documentation to the extent that such documents are included in the fields searched.\\n\"\n",
    "                        \"Electronic database consulted during the international search: EPAB\")\n",
    "\n",
    "        # DOCUMENTS CONSIDERED TO BE RELEVANT\n",
    "        header = [\"Category\", \"Citation of Document (with relevant passages)\", \"Relevant to Claim No.\"]\n",
    "        col_widths = [20, 120, 40]\n",
    "\n",
    "        rows = [\n",
    "            [\"X\", \"EP 3072376 A2 (BASF SE) - 28 September 2016\\nParagraphs: [0020], [0023]-[0024], [0028], [0055], [0058]-[0059], [0078]\", \"1-15\"],\n",
    "            [\"A\", \"CN 101014914 A (Agrium Polymer Coatings Corp) - 08 August 2007\\nClaims: 1-58\", \"1-15\"],\n",
    "            [\"A\", \"CN 103442547 A (Univ. Muenchen Tech) - 11 December 2013\\nClaims: 1-10\", \"1-15\"],\n",
    "            [\"A\", \"CN 204807546 U (Beijing Shennongyuan Biotechnology Dev. Co. Ltd) - 25 November 2015\", \"1-15\"],\n",
    "            [\"A\", \"CN 1243112 A (LI Fengjie) - 02 February 2000\\nClaims: 1-9\", \"1-15\"]\n",
    "        ]\n",
    "\n",
    "        pdf.table_with_title(\"DOCUMENTS CONSIDERED TO BE RELEVANT\", header, rows, col_widths)\n",
    "\n",
    "        # Special Categories of Cited Documents as a Table\n",
    "        header_special = [\"Category\", \"Description\"]\n",
    "        col_widths_special = [20, 150]\n",
    "\n",
    "        rows_special = [\n",
    "            [\"A\", \"Document defining the general state of the art, not considered to be of particular relevance\"],\n",
    "            [\"T\", \"Later document published after the international filing date or priority date, cited to understand the principle or theory underlying the invention\"],\n",
    "            [\"X\", \"Document of particular relevance; the claimed invention cannot be considered novel or involves no inventive step when taken alone\"],\n",
    "            [\"E\", \"Document published on or after the international filing date\"],\n",
    "            [\"O\", \"Document referring to an oral disclosure, use, exhibition, or other means\"]\n",
    "        ]\n",
    "\n",
    "        pdf.table_with_title(\"Special Categories of Cited Documents\", header_special, rows_special, col_widths_special)\n",
    "\n",
    "        # Get the current date in the format \"DD Month YYYY\"\n",
    "        today = datetime.datetime.now().strftime(\"%d %B %Y\")\n",
    "\n",
    "        # Dates\n",
    "        pdf.section_title(\"Dates\")\n",
    "        dates = f\"- Date of actual completion of the international search: {today}\\n\" \\\n",
    "                f\"- Date of mailing of the international search report: {today}\"\n",
    "        pdf.section_body(dates)\n",
    "\n",
    "        # Name and Mailing Address of the ISA/CN with Indentation\n",
    "        pdf.section_title(\"Name and Mailing Address of the ISA/CN\")\n",
    "        address = \"Confused Electrons:\\n        Arnab Saha\\n        Tran Le Phuong Lan\\n        Mauricio Rodriguez Alas\\n        Ralph Ryan Hebrio\"\n",
    "        pdf.section_body(address)\n",
    "\n",
    "        # Replace the Authorized Officer section with the provided names\n",
    "        pdf.section_title(\"Authorized Officers\")\n",
    "        authorized_officers = (\n",
    "            \"David Horat - Director of Patent Knowledge, Directorate-General 5 Legal and International Affairs\\n\"\n",
    "            \"Åsa Ribbe - Principal Director Operations, Directorate-General 1 Patent Granting Process\\n\"\n",
    "            \"Sylvia Kok-de Vries - Director of Prospects and Studies, Directorate-General 4 Corporate Services\\n\"\n",
    "            \"Franco Mascia - Data Scientist, Directorate-General 1 Patent Granting Process and Business Information Technology\\n\"\n",
    "            \"Diego Eguidazu Alonso - Chief Information Officer, Business Information Technology\"\n",
    "        )\n",
    "        pdf.section_body(authorized_officers)\n",
    "\n",
    "        # INFORMATION ON PATENT FAMILY MEMBERS\n",
    "        header_family = [\"International Application No.\", \"Application Number\"]\n",
    "        rows_family = [[application_no]]\n",
    "        col_widths_family = [80, 110]\n",
    "\n",
    "        # Output the PDF\n",
    "        output_pdf_path = os.path.join(application_folder, 'international_search_report.pdf')\n",
    "        pdf.output(output_pdf_path)\n",
    "\n",
    "        messagebox.showinfo(\"Success\", f\"Search report generated and saved as {output_pdf_path}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        messagebox.showerror(\"Error\", f\"Failed to generate search report: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Create the main window for the patent examiner interface\n",
    "root = tk.Tk()\n",
    "root.title(\"Patent Examiner Dashboard\")\n",
    "root.geometry(\"900x700\")\n",
    "\n",
    "# Header Label\n",
    "header_label = tk.Label(root, text=\"European Patent Office\", font=(\"Helvetica\", 20, \"bold\"), bg='#007acc', fg='white')\n",
    "header_label.pack(fill='x', pady=10)\n",
    "\n",
    "# Frame for the list of patent applications\n",
    "frame_left = tk.Frame(root, bg='white')\n",
    "frame_left.pack(side='left', fill='y', padx=20, pady=20)\n",
    "\n",
    "# Label for the list of applications\n",
    "application_label = tk.Label(frame_left, text=\"Submitted Patent Applications\", font=(\"Helvetica\", 12, \"bold\"), bg='white')\n",
    "application_label.pack(pady=10)\n",
    "\n",
    "# Listbox to display the patent applications\n",
    "application_listbox = tk.Listbox(frame_left, height=20, width=40)\n",
    "application_listbox.pack(pady=10)\n",
    "\n",
    "# Load submitted applications into the listbox\n",
    "applications = load_patent_applications()\n",
    "for app in applications:\n",
    "    application_listbox.insert(tk.END, app)\n",
    "\n",
    "# Bind selection event to load details\n",
    "application_listbox.bind(\"<<ListboxSelect>>\", load_application_details)\n",
    "\n",
    "# Frame for displaying details of the selected application\n",
    "frame_right = tk.Frame(root, bg='white')\n",
    "frame_right.pack(side='right', fill='both', expand=True, padx=20, pady=20)\n",
    "\n",
    "# Label for application details\n",
    "details_label = tk.Label(frame_right, text=\"Application Details\", font=(\"Helvetica\", 12, \"bold\"), bg='white')\n",
    "details_label.pack(pady=10)\n",
    "\n",
    "# Textbox to display the details of the selected application\n",
    "details_textbox = tk.Text(frame_right, wrap='word', height=20, width=60)\n",
    "details_textbox.pack(pady=10)\n",
    "\n",
    "# Button to predict IPC code\n",
    "predict_ipc_button = ttk.Button(frame_right, text=\"Predict IPC Code\", command=predict_ipc_code)\n",
    "predict_ipc_button.pack(pady=10)\n",
    "\n",
    "# ** New ** Label to display Patent Title - Classification (IPC)\n",
    "title_ipc_label = tk.Label(frame_right, text=\"\", font=(\"Helvetica\", 12, \"bold\"), bg='white', fg='blue')\n",
    "title_ipc_label.pack(pady=10)\n",
    "\n",
    "# Start the main loop\n",
    "root.mainloop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Aro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
